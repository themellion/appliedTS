---
title: "Box-Jenkins Methodology"
---

```
```
## Introduction
\justify
Autoregressive Moving Average (ARMA) and autoregressive Integrated Moving Average (ARIMA) models are part of what is know as the Box-Jenkins methodology which is very useful in forecasting future values of a time-series having values that are statistically dependent upon or related to each other.  
There are several steps involved in applying the Box-Jenkins apprach. Specifically:  

* *identification*
* *estimation*
* *diagnostic checking*
* *forecasting*

The Box-Jenkions approach chooses a particular time-series model to be used from a class of stationary time-series models. Models in this class are either autoregressive models (AR), moving average models (MA), or mixed autoregressive-moving-average models (ARMA). These models are capable of representing both seasonal and non-seasonal time-series. Overall, the Box-Jenkins methodology is capable of accurately forecasting time-series with complicated error structures.  
The regression and exponential smoothing approaches to forecasting assume that the values of the time-series being forecaste are statistically independent of or not related to each other. If the values of the time-series being forecasted are statistically dependent upon or related to each other, then the Box-Jenkins methodology uses the dependency to produce forecasts that are likely to be more accurate than the forecasts produced by the regression and exponential smoothing approaches.  
Regression and exponential smoothing approaches in forecasting, which are presented in the other sections of the course assume that the random error components in the time-series model are statistically independent of each other. 

$$y_t=f(\beta_0,\beta_1,\ldots,\beta_p;t)+\epsilon$$

In such a model, if the successive error-terms are statistically independent, then so are the successive observations of the time-series. However, if the successive error terms are statistically dependent upon each other, then so are the successive observations, and we then call the observations *autocorrelated*. It then follows that accurate forecasting of the time-series can probably best be accomplished by employing a model that express $y_t$ as a function of present and prior random error components, 

$$y_t=\mu+\psi_0\epsilon_t+\psi_1\epsilon_{t-1}+\psi_2\epsilon_{t-2}+\ldots$$
where $\epsilon_t,\epsilon_{t-1},\ldots$ are present and prior random error components and where $\mu, \psi_t, \psi_1, \psi_2, \ldots$ are the parameters of the model. In this model it is assumed that the error terms $\epsilon_t,\epsilon_{t-1},\epsilon_{t-2},\ldots$ are independent and normally distributed with mean 0 and equal variances. However, it is clear that successive values of the time-series in this model are dependent, because they are functions of some common error terms.  
The Box-Jenkins methodology first develops an appropriate time-series model for use in forecasting. This development consists of a three-step iterative procedure. The first step is called *identification*. In this step a tentative model is identified by analysis of the historical data. The second step is called *estimation*. In this step the unknown parameters of the tentative model are estimated. The third step is called *diagnostic checking*. In this step diagnostic checks are performed to test the adequacy of the model, and, if need be, to suggest potential improvements. Once a time-series model has been developed, a fourth step, called forecasting, generates predictions of future values of the time-series.  
In practice, regression and exponential smoothing models are frequently applied with good results to forecasting time-series with dependent or autocorrelated observations. However, since Box-Jenkins methodology uses the dependency in the observations more effectively than do regression and exponential smoothing, the Box-Jenkins methodology is likely to produce more accurate forecasts. Moreover, the Box-Jenkins methodology offers a more systematic approach to building, analysing and forecasting with time-series. However, the Box-Jenkins methodology has several drawbacks. First, at least 50 observations are needed to build a good Box-Jenkins model. Hence, Box-Jenkins models are best used to analyse time-series in which the sampling interval is small so that a fairly long history of data can be accummulated. The Box-Jenkins methodology has thus frequently been applied to time-series that generate hourly, daily or weekly observations. When monthly or yearly data is collected, the sampling interval may be fairly long and there may not be enough historical data available to develop a good Box-Jenkins model, or if the history of data is long enough to provide sufficient data for the model, the underlying process generating the time-series may be changing. Thus the first part of the process history may be useless in determining the current nature of the underlying process. For time-series exhibiting seasonal variation, the problem is more serious, because each complete year of history is essentially a single observation. Another disadvantage of Box-Jenkins methodology is that there are no available automatic procedures to either update the estimates of the model as new data are observed or to determine and adapt to changes in the underlying process generating the time-series (exponential smoothing offers this functionality). A final disadvantage of Box-Jenkins methodology is that it considered time-consuming and costly compared to exponential smoothing and linear regression approaches.  

## ARMA 

## ARIMA 



```
```
